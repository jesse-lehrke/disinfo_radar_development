{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import lxml\n",
    "\n",
    "import json\n",
    "#from dateutil import rrule\n",
    "\n",
    "## needs a py file to import properly in this structure\n",
    "#from utils.collection_utils import datetime_parse\n",
    "\n",
    "from itertools import combinations, permutations, chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/'\n",
    "IN_DATA_PATH = '../data/input_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !!! Datetime function needs work\n",
    "\n",
    "If the month dict makes a replacement, need to tag that as a month and limit my permutations as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from itertools import combinations, permutations, chain\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def datetime_parse(x):\n",
    "      '''\n",
    "      Parse datetime out of a string\n",
    "      More functionality should be added as issues encountered \n",
    "      Has some serious issues as it stands... not a hard fix, but time consuming \n",
    "      '''\n",
    "      # Remove all non-alpha-numeric\n",
    "      out = re.sub(r'[^0-9a-zA-Z:]+', ' ', x)\n",
    "\n",
    "      ## Remove any starting tag with :\n",
    "      # out.split('Updated: ', expand=True)\n",
    "      \n",
    "      # Remove time \n",
    "      out.replace(r'\\b(([0-9]|0[0-9]|1[0-9]|2[0-3]):[0-5][0-9](:[0-5][0-9])?\\s?([AaPp][Mm])?)', ' ')\n",
    "      \n",
    "      # Not needed\n",
    "      month_dict = {\n",
    "      'January':'1', 'February':'2', 'March':'3', 'April':'4', 'May':'5', 'June':'6',\n",
    "      'July':'7', 'August':'8', 'September':'9', 'October':'10', 'November':'11', \n",
    "      'December':'12', 'Jan':'1', 'Feb':'2', 'Mar':'3', 'Apr':'4', 'May':'5',\n",
    "      'Jun':'6', 'Jul':'7', 'Aug':'8', 'Sep':'9', 'Oct':'10', 'Nov':'11', 'Dec':'12'\n",
    "      }\n",
    "\n",
    "      # Not needed, replaces months with number value, but strtime does that\n",
    "      #out = [out.replace(key, value) for key, value in month_dict.items() if key in out][0]\n",
    "      \n",
    "      # Removing digits longer than 4 long\n",
    "      out = re.sub(r'[0-9]\\d{4,}', ' ', out)\n",
    "      #out = re.sub(r'[0-9]+:[0-9]+', ' ', out) #  not sure what this was for\n",
    "      \n",
    "      # Removing all non-digits and words not in months\n",
    "      out = out.split(' ')\n",
    "      out = [word for word in out if word.isdigit() or word in list(month_dict.keys())]\n",
    "      out = ' '.join(out[:3])\n",
    "      \n",
    "      # Strip loose whitespace\n",
    "      out = out.strip()\n",
    "\n",
    "      # Lists for parsing\n",
    "      month = ['%b', '%m', '%B']\n",
    "      day = ['%d']\n",
    "      year = ['%Y', '%y']\n",
    "\n",
    "      varieties = list(permutations(chain(year, day, month), 3))\n",
    "      for v in varieties:\n",
    "            v = ' '.join(v)\n",
    "            try:\n",
    "                  date = [datetime.strptime(str(out), v)]# if d != 0 else d for d in out] #old tag used elsewhere, here for ref.\n",
    "                  print(date)\n",
    "                  if date is not None:\n",
    "                        print('Successfully parsed with format: ' + v)\n",
    "                        return date[0]\n",
    "                        break\n",
    "            except:\n",
    "                  #print('Failed: ' + v)\n",
    "                  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = '2020 01 23'\n",
    "date = datetime_parse(str1)\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To load as dataframe: no value at present \n",
    "\n",
    "# load_file = IN_DATA_PATH + 'collection_urls_df.jsonl'\n",
    "\n",
    "# df = pd.read_json(load_file, convert_dates=True, lines=True, orient='records')\n",
    "# df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_file = IN_DATA_PATH + 'collection_urls_dict.json'\n",
    "\n",
    "with open(load_file) as handle:\n",
    "    sources = json.loads(handle.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get today's date\n",
    "# To do: create a \"last scraped json\"\n",
    "today = datetime.now()\n",
    "\n",
    "today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists for saving collected data\n",
    "\n",
    "title_list = []\n",
    "url_list = []\n",
    "dates = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = sources['Import_AI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all Import AI issues with date, title, and link\n",
    "\n",
    "response = requests.post(base_url) #headers=header)\n",
    "\n",
    "html = soup(response.text, 'lxml')\n",
    "\n",
    "objects = html.find_all('li', class_=\"campaign\")\n",
    "for obj in objects:\n",
    "      print(obj.text)\n",
    "      print(obj.a['href'])\n",
    "      title_list.append(obj.text)\n",
    "      url_list.append(obj.a['href'])\n",
    "\n",
    "print('------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse date from list\n",
    "\n",
    "for item in title_list:\n",
    "      date = item.split(' -')[0]\n",
    "      print(date)\n",
    "      date_parsed = datetime.strptime(date, '%m/%d/%Y')\n",
    "      print(date_parsed)\n",
    "      #date_sequence = datetime_parse(item)\n",
    "      #dates.append(date_sequence[0])\n",
    "      dates.append(date_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save collection to dataframe\n",
    "\n",
    "df_collected = pd.DataFrame(list(zip(title_list, url_list, dates)), \n",
    "            columns=['title', 'url', 'date'])\n",
    "\n",
    "df_collected.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_collected.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter keywords in json referenced here\n",
    "\n",
    "# For testing only\n",
    "#search_terms = ['DeepMind', 'Google']\n",
    "\n",
    "load_file = IN_DATA_PATH + 'collection_searchterms.json'\n",
    "\n",
    "with open(load_file) as handle:\n",
    "    search_terms = json.loads(handle.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms['search_term']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to save to\n",
    "relevant_text = []\n",
    "\n",
    "#preping list fo dictionary conversion\n",
    "relevant_text.append(['title', 'url', 'date', 'text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets text for results within timedelta window\n",
    "#     This is probably best changed to a \"last scraped\" date from a json\n",
    "\n",
    "for index, row in df_collected.iterrows():\n",
    "      if row.date >= today - timedelta(days=30):\n",
    "            print('Fetching: ' + row.url)\n",
    "            response = requests.post(row.url) #headers=header)\n",
    "\n",
    "            html = soup(response.text, 'lxml')\n",
    "\n",
    "            objects = html.find_all('p')#, class_=\"campaign\")\n",
    "            issue_text = []\n",
    "            for obj in objects:\n",
    "                  issue_text.append(obj.text)\n",
    "                  #print(obj.text)\n",
    "            issue_text = ' '.join(issue_text)\n",
    "            #print(issue_text)\n",
    "            #print('--------------------------------')\n",
    "            \n",
    "            for word in search_terms['search_term']:\n",
    "                  if word in issue_text:\n",
    "                        save = list(row)\n",
    "                        save.append(issue_text)\n",
    "                        relevant_text.append(save)                  \n",
    "                        print('Search term found: ' +  word)\n",
    "                        break\n",
    "                  else: \n",
    "                        pass\n",
    "            time.sleep(5)\n",
    "      else:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(relevant_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## To save to json - not recommend as datetimes not serializable, would have to convert dt back to string\n",
    "# Note - ugly dictionary, e.g. not jsonl or indented, but kept simple unless requested\n",
    "\n",
    "# data_dict = {k: v for k, *v in zip(*relevant_text)}\n",
    "\n",
    "# with open('data.json', 'w') as f:\n",
    "#     json.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(relevant_text[1:],columns=relevant_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: add if file clause\n",
    "old_df = pd.read_csv(DATA_PATH + 'open_ai_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([new_df, old_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If timing for collection and timedelta etc are good, should not be needed, but good to be sure\n",
    "# If you instead have date issues, you should do this in the collect loop to eliminate unneeeded collectio\n",
    "# e.g. if url in list(old_df.url): pass\n",
    "\n",
    "combined_df.drop_duplicates(subset='url', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(DATA_PATH + 'open_ai_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = sources['Synced']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just checking\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get date part for url\n",
    "year = datetime.now().year\n",
    "month = datetime.now().month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_url = base_url + str(year) + '/' +  str(month) + '/'\n",
    "current_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists for saving\n",
    "title_list = []\n",
    "url_list = []\n",
    "summary_list = []\n",
    "date_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a fake useragent\n",
    "# Can do for all collections, but for now limited to where is seems necessary only\n",
    "# Ignore the error \n",
    "\n",
    "ua = UserAgent(verify_ssl=False, cache=False)\n",
    "\n",
    "user_agent = ua.random\n",
    "header = {'User-Agent': user_agent}\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(url, headers=header)\n",
    "\n",
    "html = soup(response.text, 'lxml')\n",
    "\n",
    "obj = html.find('div',id= \"primary\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dates = obj.find_all(class_='entry-date')\n",
    "for d in dates:\n",
    "      d_parsed = datetime_parse(d.text)\n",
    "      date_list.append(d_parsed[0])\n",
    "      #date_list.append(d.text)\n",
    "\n",
    "titles = obj.find_all(class_='entry-title')\n",
    "for t in titles:\n",
    "      title_list.append(t.text)\n",
    "      url_list.append(t.a['href'])\n",
    "\n",
    "summaries = obj.find_all(class_='entry-summary')\n",
    "for s in summaries:\n",
    "      summary_list.append(s.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_collected2 = pd.DataFrame(list(zip(title_list, url_list, date_list, summary_list)), \n",
    "            columns=['title', 'url', 'date', 'summary'])\n",
    "\n",
    "df_collected2.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keyword = 'AlexNet'\n",
    "search_terms['search_term']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_text = []\n",
    "\n",
    "relevant_text.append(['title', 'url', 'date', 'summary', 'text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_collected2.iterrows():\n",
    "      if row.date >= today - timedelta(days=14):\n",
    "            print('Fetching: ' + row.url)\n",
    "            response = requests.post(row.url) #headers=header)\n",
    "\n",
    "            html = soup(response.text, 'lxml')\n",
    "\n",
    "            objects = html.find_all('div', class_=\"entry-content\")\n",
    "            article_text = []\n",
    "            for obj in objects:\n",
    "                  paragraph_text = obj.find_all('p')\n",
    "                  for p in paragraph_text:\n",
    "                        article_text.append(p.text)\n",
    "                  #print(obj.text)\n",
    "            article_text = ' '.join(article_text)\n",
    "\n",
    "            for word in search_terms['search_term']:\n",
    "                  if word in article_text:\n",
    "                        save = list(row)\n",
    "                        save.append(article_text)\n",
    "                        relevant_text.append(save)                  \n",
    "                        print('Search term found: ' +  word)\n",
    "                        break\n",
    "            else: \n",
    "                  pass\n",
    "\n",
    "            time.sleep(5)\n",
    "      else:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(relevant_text[1:],columns=relevant_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: add if file clause\n",
    "old_df = pd.read_csv(DATA_PATH + 'synced_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([new_df, old_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If timing for collection and timedelta etc are good, should not be needed, but good to be sure\n",
    "# If you instead have date issues, you should do this in the collect loop to eliminate unneeeded collectio\n",
    "# e.g. if url in list(old_df.url): pass\n",
    "\n",
    "combined_df.drop_duplicates(subset='url', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(DATA_PATH + 'synced_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = sources['MIT_Technology_Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_designator = 'topic/'\n",
    "topic_tags = ['artificial-intelligence', 'humans-and-technology', 'computing'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_url = base_url + topic_designator + topic_tags[0]\n",
    "final_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in topic_tags:\n",
    "      final_url = base_url + topic_designator + tag\n",
    "      # then search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(final_url)\n",
    "\n",
    "# print headers of response\n",
    "print(response.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_ROOT_URL = \"https://wp.technologyreview.com/wp-json/irving/v1/data/term_archive?category_name=artificial-intelligence&page=1\"\n",
    "'''\n",
    "API_ROOT_URL\n",
    "slug\n",
    "?\n",
    "requestType\n",
    "=\n",
    "query\n",
    "&page=1'''\n",
    "\n",
    "def searchApi():\n",
    "    endpoint = API_ROOT_URL\n",
    "    data = {\n",
    "        \"slug\": \"term_archive\",\n",
    "        \"requestType\": \"category_name\",\n",
    "        \"query\": \"artificial-intelligence\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(endpoint)#, data=data)\n",
    "        if(response.status_code == 200):\n",
    "            #print(response.json())\n",
    "            for msg in response:\n",
    "                print(msg)\n",
    "    except Exception:\n",
    "        print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchApi()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_Link = \"https://wp.technologyreview.com/wp-json/irving/v1/data/term_archive?category_name=\"\n",
    "#artificial-intelligence\"\n",
    "#&page=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a get test request\n",
    "try:\n",
    "      response = requests.get(API_Link)\n",
    "\n",
    "      # print headers of response\n",
    "      if(response.status_code == 200):\n",
    "            print(response.headers)\n",
    "            \n",
    "except Exception:\n",
    "      print(traceback.format_exc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(API_Link, pages=1):\n",
    "    with requests.get(API_Link + '&page=' + str(pages)) as response:\n",
    "        page_soup = soup(response.content, 'lxml')\n",
    "        return page_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "\n",
    "for tag in topic_tags:\n",
    "      response = get_response(API_Link + tag, pages=str(1))\n",
    "\n",
    "      #parse\n",
    "      j_response = json.loads(response.text)\n",
    "      responses = responses + j_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses[1]['config'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial empty df\n",
    "collected_df = pd.DataFrame(columns=['title', 'url', 'date', 'summary'])\n",
    "collected_df.loc[collected_df.index, :] = ['x', 'url', 'date', 'summary']\n",
    "\n",
    "collected_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_keys = ['title', 'permalink', 'postDate', 'excerpt']\n",
    "\n",
    "entries = []\n",
    "entries.append(['title', 'url', 'date', 'summary'])\n",
    "\n",
    "for item in responses:\n",
    "      entry = [item['config'][key] for key in needed_keys]\n",
    "      entries.append(entry)\n",
    "      #collected_df.loc[collected_df.index.max() + 1, :] = entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(entries[1:],columns=entries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_from_url(x):\n",
    "\n",
    "      pat = r\"(20[0-2][0-9]([-_/]?)[0-9]{2}(?:\\2[0-9]{2})?)\"\n",
    "      dates = re.compile(pat)\n",
    "\n",
    "      res = dates.search(x)\n",
    "\n",
    "      res = datetime_parse(res[0])\n",
    "  \n",
    "      return res[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['date'] = new_df['url'].apply(lambda x: date_from_url(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_text = []\n",
    "\n",
    "relevant_text.append(['title', 'url', 'date', 'summary', 'text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in new_df.iterrows():\n",
    "      if row.date >= today - timedelta(days=7):\n",
    "            print('Fetching: ' + row.url)\n",
    "            response = requests.post(row.url, headers=header)\n",
    "\n",
    "            html = soup(response.text, 'lxml')\n",
    "\n",
    "            objects = html.find_all('div', id=\"content--body\")\n",
    "            article_text = []\n",
    "            for obj in objects:\n",
    "                  paragraph_text = obj.find_all('p')\n",
    "                  for p in paragraph_text:\n",
    "                        article_text.append(p.text)\n",
    "                  #print(obj.text)\n",
    "            article_text = ' '.join(article_text)\n",
    "\n",
    "            for word in search_terms['search_term']:\n",
    "                  if word in article_text:\n",
    "                        save = list(row)\n",
    "                        save.append(article_text)\n",
    "                        relevant_text.append(save)                  \n",
    "                        print('Search term found: ' +  word)\n",
    "                        break\n",
    "            else: \n",
    "                  pass\n",
    "\n",
    "            time.sleep(5)\n",
    "      else:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df2 = pd.DataFrame(relevant_text[1:],columns=relevant_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: add if file clause\n",
    "old_df = pd.read_csv(DATA_PATH + 'synced_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([new_df, old_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If timing for collection and timedelta etc are good, should not be needed, but good to be sure\n",
    "# If you instead have date issues, you should do this in the collect loop to eliminate unneeeded collectio\n",
    "# e.g. if url in list(old_df.url): pass\n",
    "\n",
    "combined_df.drop_duplicates(subset='url', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(DATA_PATH + 'mit_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IEEE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Currently not working well - only 4 returns due to dynamic scrolling\n",
    "I can solve with Selenium, but trying to avoid using it\n",
    "\n",
    "Currently working on a requests version, but convoluated urls and html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Can get all the rest (set range based on date) but missed first page returned\n",
    "\n",
    "counter = 0\n",
    "for i in range(1, 5): #while\n",
    "      url = \"https://spectrum.ieee.org/res/load_more_posts/data.js?site_id=20265424&node_id=/root/blocks/block[search]/abtests/abtest[1]/row/column[1]/choose/when[getparams.order]/choose/otherwise/element_wrapper-&resource_id=search_deepfake&path_params={}&formats=html&q=deepfake&topic=&order=newest&rm_lazy_load=16&pn=%s&pn_strategy=\" % (counter)\n",
    "      #url = \"https://spectrum.ieee.org/res/load_more_posts/data.js?site_id=20265424&node_id=/root/blocks/block[search]/abtests/abtest[1]/row/column[1]/choose/otherwise/choose/otherwise/element_wrapper-&resource_id=search_deepfake&path_params={}&formats=html&q=deepfake&order=newest&rm_lazy_load=1&pn=%s&pn_strategy=\" % (counter)\n",
    "      print(url)\n",
    "      counter +=1\n",
    "      # ua = UserAgent(verify_ssl=False, cache=False)\n",
    "\n",
    "      # user_agent = ua.random\n",
    "      # header = {'User-Agent': user_agent}\n",
    "\n",
    "      response = requests.post(url)#, headers=header)\n",
    "\n",
    "      html = soup(response.text, 'lxml')\n",
    "\n",
    "      objects = html.find('div')#, class_='posts-wrapper')#elid=True)#class_= 'clearfix')\n",
    "\n",
    "      for obj in objects:\n",
    "            items = obj.find_all('span')\n",
    "            for it in items:\n",
    "                  print(it.text)\n",
    "            items = obj.find_all('h2')#, class_ = 'widget__head')#, id='col-right')\n",
    "            #print(len(items))\n",
    "            for i in items:\n",
    "                  print(i.text)\n",
    "                  print(i.a['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url ='https://spectrum.ieee.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_url = 'https://spectrum.ieee.org/search/?q='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_url = 'https://spectrum.ieee.org/topic/artificial-intelligence/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query connector\n",
    "C = \"&\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_criteria = \"order=newest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_criteria = \"topic=artificial-intelligence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialized above\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today.date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_to = today.date() - timedelta(days=30)\n",
    "back_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_terms['search_term']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for term in search_terms['search_term']:\n",
    "      final_url = query_url + term + C + sort_criteria\n",
    "      print(final_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_url)\n",
    "ua = UserAgent(verify_ssl=False, cache=False)\n",
    "\n",
    "user_agent = ua.random\n",
    "header = {'User-Agent': user_agent}\n",
    "\n",
    "response = requests.post(final_url, headers=header)\n",
    "\n",
    "html = soup(response.text, 'lxml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = []\n",
    "url_list = []\n",
    "date_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Works some at least but only fetches top 4 due to page scroll\n",
    "\n",
    "objects = html.find_all('div',  class_='section_column')#elid=True)#class_= 'clearfix')\n",
    "\n",
    "for obj in objects:\n",
    "      items = obj.find_all('div', id='col-right')\n",
    "      print(len(items))\n",
    "      for i in items:\n",
    "\n",
    "            print(i.h2.text)\n",
    "            title_list.append(i.h2.text)\n",
    "\n",
    "            print(i.h2.a['href'])\n",
    "            url_list.append(i.h2.a['href'])\n",
    "\n",
    "            date = i.div.span\n",
    "            print(date.text)\n",
    "            try: \n",
    "                  #not working well\n",
    "                  d_parsed = datetime_parse(date.text)\n",
    "                  date_list.append(d_parsed[0])\n",
    "            except:\n",
    "                  date_list.append('None')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_collected3 = pd.DataFrame(list(zip(title_list, url_list, date_list)), \n",
    "            columns=['title', 'url', 'date',])\n",
    "\n",
    "df_collected3.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to save to\n",
    "relevant_text = []\n",
    "\n",
    "#preping list fo dictionary conversion\n",
    "relevant_text.append(['title', 'url', 'date', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_collected3.iterrows():\n",
    "      if row.date >= today - timedelta(days=30):\n",
    "            print('Fetching: ' + row.url)\n",
    "            response = requests.post(row.url) #headers=header)\n",
    "\n",
    "            html = soup(response.text, 'lxml')\n",
    "\n",
    "            objects = html.find_all('div', id=\"col-center\")\n",
    "            article_text = []\n",
    "            for obj in objects:\n",
    "                  paragraph_text = obj.find_all('p')\n",
    "                  for p in paragraph_text:\n",
    "                        article_text.append(p.text)\n",
    "                  #print(obj.text)\n",
    "            article_text = ' '.join(article_text)\n",
    "   \n",
    "            for word in search_terms['search_term']:\n",
    "                  if word in article_text:\n",
    "                        save = list(row)\n",
    "                        save.append(article_text)\n",
    "                        relevant_text.append(save)                  \n",
    "                        print('Search term found: ' +  word)\n",
    "                        break\n",
    "            else: \n",
    "                  pass\n",
    "\n",
    "            time.sleep(5)\n",
    "      else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(relevant_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  urllib.request import urlopen\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_url_1 = 'https://www.cna.org/centers/cna/sppp/rsp/russia-ai-archive#newsletters'\n",
    "base_url_2  = \"https://www.cna.org/our-media/newsletters/china-ai-and-autonomy-report?index=true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert PDF \n",
    "# clean up PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2022, 5, 6, 11, 42, 35, 686736)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = datetime.now()\n",
    "\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2022, 4, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back_to = today.date() - timedelta(days=30)\n",
    "back_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create loop over base_url_1 and_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error occurred during loading data. Trying to use cache server https://fake-useragent.herokuapp.com/browsers/0.1.11\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jesselehrke/Documents/GitHub/disinfo_radar_development/dri_venv/lib/python3.9/site-packages/fake_useragent/utils.py\", line 154, in load\n",
      "    for item in get_browsers(verify_ssl=verify_ssl):\n",
      "  File \"/home/jesselehrke/Documents/GitHub/disinfo_radar_development/dri_venv/lib/python3.9/site-packages/fake_useragent/utils.py\", line 99, in get_browsers\n",
      "    html = html.split('<table class=\"w3-table-all notranslate\">')[1]\n",
      "IndexError: list index out of range\n"
     ]
    }
   ],
   "source": [
    "ua = UserAgent(verify_ssl=False, cache=False)\n",
    "\n",
    "user_agent = ua.random\n",
    "header = {'User-Agent': user_agent}\n",
    "\n",
    "response = requests.get(base_url_2, headers=header)\n",
    "\n",
    "html = soup(response.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = []\n",
    "url_list = []\n",
    "date_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "objects = html.find_all('div', class_='two-column-layout')#, href=True)#elid=True)#class_= 'clearfix')\n",
    "print(len(objects))\n",
    "\n",
    "for obj in objects:\n",
    "      items = obj.find_all('li')#, href=True)\n",
    "      print(len(items))\n",
    "      for i in items:\n",
    "            print(i.text)\n",
    "            title_list.append(i.text)\n",
    "\n",
    "            urls = i.find('a', href=True)\n",
    "            #print(urls['href'])\n",
    "            url_list.append('https://www.cna.org' + urls['href'])\n",
    "\n",
    "            date = i.text\n",
    "            date = date.split(', ')[1:]\n",
    "            date = ' '.join(date).strip()\n",
    "            #date = date.strip()\n",
    "            print(date)\n",
    "            date_parsed = datetime.strptime(date, '%B %d %Y')\n",
    "            date_list.append(date_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, url, date]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save collection to dataframe\n",
    "\n",
    "df_collected = pd.DataFrame(list(zip(title_list, url_list, date_list)), \n",
    "            columns=['title', 'url', 'date'])\n",
    "\n",
    "df_collected.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEB REDESIGN\n",
    "test_url = 'https://www.cna.org/our-media/newsletters/china-ai-and-autonomy-report/issue-14'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(test_url, headers=header)\n",
    "\n",
    "html = soup(response.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_header = html.find('h1').text\n",
    "issue_header = html.find('h2').text.strip()\n",
    "issue_header = issue_header.split('\\r')[0]\n",
    "title = main_header + ': ' + issue_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "objects = html.find('section', class_='content-rows')\n",
    "\n",
    "header_list = []\n",
    "try:\n",
    "      full_text = objects.text.split('NOTES')[0]\n",
    "except:\n",
    "      full_text = objects.text\n",
    "\n",
    "headers = objects.find_all('strong')\n",
    "for head in headers:\n",
    "      if head.text == '':\n",
    "            pass\n",
    "      else:\n",
    "            header_list.append(head.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_article_on(txt, seps):\n",
    "    '''\n",
    "    Splits a full text article on a list of seperators\n",
    "    '''\n",
    "    default_sep = seps[0]\n",
    "\n",
    "    # we skip seps[0] because that's the default separator\n",
    "    for sep in seps[1:]:\n",
    "        txt = txt.replace(sep, default_sep)\n",
    "    return [i.strip() for i in txt.split(default_sep)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = split(full_text, header_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(header_list) != len(articles):\n",
    "      header_list.insert(0, 'Intro (no tag)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "print(len(header_list))\n",
    "print(len(articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_list = [title + ' - ' + head for head in header_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The China AI and Autonomy Report: Issue 14, May 5, 2022 - Intro (no tag)',\n",
       " 'The China AI and Autonomy Report: Issue 14, May 5, 2022 - DJI suspends operations in Russia and Ukraine amidst continued controversy over the use of its UAVs in the Ukraine conflict.',\n",
       " 'The China AI and Autonomy Report: Issue 14, May 5, 2022 -  PLA National Defense University (NDU) professor argues that cognitive warfare operations in the Russia-Ukraine War represents the future of warfare. ',\n",
       " 'The China AI and Autonomy Report: Issue 14, May 5, 2022 -   Trend 1: From the \"strong beating the weak\" to the \"intelligent beating the dull.\"  ',\n",
       " 'The China AI and Autonomy Report: Issue 14, May 5, 2022 -  Trend 2: From \"destructive power\" to \"manipulating cognition. ',\n",
       " 'The China AI and Autonomy Report: Issue 14, May 5, 2022 -  Trend 3: From \"human-based\" to \"human-machine collaboration.\" ',\n",
       " 'The China AI and Autonomy Report: Issue 14, May 5, 2022 -  Trend 4: From \"big eats small\" to \"fast eats slow.\" ',\n",
       " 'The China AI and Autonomy Report: Issue 14, May 5, 2022 -   Trend 5: From \"winning through integration\" to \"winning through clusters.\"  ',\n",
       " 'The China AI and Autonomy Report: Issue 14, May 5, 2022 -  Trend 6: From \"military dominance\" to \"hybrid warfare.\" ',\n",
       " 'The China AI and Autonomy Report: Issue 14, May 5, 2022 -  Trend 7: From \"practical test\" to \"experimental exercise.\" ',\n",
       " 'The China AI and Autonomy Report: Issue 14, May 5, 2022 - PLA Daily article calls battle management systems the \"core\" of modern combat systems.',\n",
       " 'The China AI and Autonomy Report: Issue 14, May 5, 2022 - PLA Daily article emphasizes role of software assurance in future combat systems.',\n",
       " 'The China AI and Autonomy Report: Issue 14, May 5, 2022 - PLA Daily article predicts that the metaverse will improve training.',\n",
       " 'The China AI and Autonomy Report: Issue 14, May 5, 2022 - PLA Daily article discusses essential role of cognitive warfare in future warfare.',\n",
       " 'The China AI and Autonomy Report: Issue 14, May 5, 2022 - Chinese Academy of Sciences publishes AI principles for climate action.',\n",
       " 'The China AI and Autonomy Report: Issue 14, May 5, 2022 - The PRC Ministry of Industry and Information Technology (MIIT) sets deadline for software developers to ensure that mobile internet applications follow new privacy and user rights regulations.',\n",
       " 'The China AI and Autonomy Report: Issue 14, May 5, 2022 - City of Beijing grants first permits for autonomous driving in China to ride-hailing rivals Baidu and Pony.ai.',\n",
       " 'The China AI and Autonomy Report: Issue 14, May 5, 2022 - Baidu announces lead in global patent applications for deep learning and autonomous driving.']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Welcome to the China AI and Autonomy Report, a biweekly newsletter published by CNA.\n",
      "Authors in the PLA Daily consider the best way forward for evaluating intelligent command systems, emphasizing the importance of integrating actual command parameters into assessing their effectiveness. PLA researchers have made a breakthrough in using an AI system with a satellite video to better identify and track objects such as planes and cars. The Cyberspace Administration of China has launched a campaign targeting the use of recommendation algorithms in internet companies. The campaign has an explicit focus on large, socially influential internet platforms, which has caused speculation that it is likely an effort to rein in social media giants Tencent and TikTok's parent company Bytedance. PRC ministries have also released a scientific and technology development plan for its transportation sector that seeks to integrate \"intelligent\" technologies into many aspects of transportation, including logistics, infrastructure, traffic monitoring, and vehicles for land, sea, and air transit. Meanwhile, the Beijing Academy of Artificial Intelligence (BAAI) has issued an apology to a Google Brain research scientist who accused PRC researchers from BAAI and other prestigious PRC institutions and corporations of committing plagiarism in a BAAI publication on machine learning. Also of note, this month another of China's \"AI dragons,\" the facial recognition giant CloudWalk Technologies, announced plans to go public.\n",
      "Intelligent Military Command Systems\n",
      "\n",
      "PLA Daily discusses requirements for properly evaluating intelligent command systems. The PLA Daily, the official newspaper of the PLA, published an  article  on how best to assess the performance of intelligent command systems.  [1]  The authors write that current assessments of intelligent command systems rely on gaming technologies that overemphasize scores and win-loss rates at the expense of using actual command parameters as measures of effectiveness. They argue that the ability to carry out core command activities (e.g., maintaining situational awareness, rapid decision-making, sound strategic and tactical design, thorough planning, efficient control, and flexible response) is a better criterion for evaluating intelligent command systems. In this respect, the authors argue that evaluations of intelligent command systems involve:\n",
      "\n",
      "Evaluations of situational awareness capabilities.  Criteria for evaluating situational awareness capabilities include the ability to assess enemy and friendly dispositions, perceive changes in the situation in real-time, and make predictions about the future battlefield situation.\n",
      "Evaluations of operational decision-making.  Criteria for evaluating operational decisions include the ability to make systematic, rational, and innovative decisions. Effective evaluations include assessing the ability of intelligent command systems to deal with major changes that occur during operations, use standardized procedures, inherit content, and make timely decisions.\n",
      "Evaluations of the ability to formulate plans. Criteria for evaluating the ability to formulate plans include the ability to retrieve and prioritize pre-determined solutions, accurately and rationally match plans to the situation and operational objectives, differentiate between forces, and design operations according to specific plans and capabilities.\n",
      "Evaluations of command and control capabilities. Criteria for evaluating command and control capabilities include the ability to issue timely and complete instructions to each subordinate unit, the ability to command and control multiple units effectively, and the ability to issue commands based on changes to the battlefield situation.\n",
      "\n",
      "\n",
      "To conduct these assessments, the authors argue that an effective evaluation team must be composed of functional experts who can evaluate military decision-making, technical experts who can properly evaluate intelligent system technology, and technology specialists who can support the team.\n",
      "Governance and Law\n",
      "\n",
      "The Cyberspace Administration of China (CAC) launches a campaign targeting the use of algorithms in large PRC internet enterprises (see original text here and translation from DigiChina  here  ).  [2]  On April 8, CAC announced \"Clear 2022 Comprehensive Governance of Algorithms\"-a campaign to ensure that corporate algorithms comply with the recently adopted  Internet Information Service Algorithmic Recommendation Management Provisions  (hereafter referred to as Provisions). The campaign will be held from April 8 until the beginning of December 2022 and will target \"large-scale websites, platforms, and products that have relatively strong public opinion properties or the capacity for social mobilization.\"\n",
      " According to Bloomberg  , although the campaign does not mention specific companies, it explicitly targets large, socially influential platforms, a possible reference to ByteDance and Tencent. The campaign is seen as part of a broader effort that began in 2020 to rein in the influence of Big Tech in China.  [3] \n",
      "\"Intelligent\" technologies feature heavily in the recently publicized PRC science and technology development plan for the field of transportation. On April 6, the Ministry of Transportation and the Ministry of Science and Technology publicly released the \"Outline for the Medium- and Long-term Development Plan for Scientific and Technological Innovation in the Transportation Sector (2021-2035)\" (see from PRC government  here  ).  [4]  By 2035, the plan aims for China to be at the \"forefront of the world\" in terms of its overall level of innovation in science and technology for transportation. The plan's goals that involve the use of \"intelligent\" technologies include the following:\n",
      "\n",
      "Make advances in infrastructure monitoring, maintenance, and performance using intelligent technologies.\n",
      "Further integrate intelligent technologies into road, rail, sea, and air travel. This includes making intelligent and autonomous vehicles for transit and using intelligent technologies to manage and monitor the transportation environments in each of these areas.\n",
      "Accelerate the adoption of smart logistics, using intelligent technologies to enable better coordination between various modes of transportation and to improve the efficiency of warehousing, sorting, and delivery.\n",
      "\n",
      "It is important to note that, although the outline lists many technologies that the PRC aspires to advance and adopt, it does not provide details on entities that may be responsible for the development of specific technologies or provide specific budget allocations for R&D.\n",
      "Industry\n",
      "\n",
      "Another one of China's \"AI dragons\" plans to go public. On April 6, CloudWalk Technology, \"an AI platform specializing in facial recognition,\" received approval from the China Securities Regulatory Commission to pursue an IPO on the Shanghai Stock Exchange.  [5]  According to a Beijing-based industry publication, CloudWalk will use the funds for a \"human-machine collaborative operating system upgrade project\" referred to as the Qingzhou KaaS Cloud Ecosystem. CloudWalk Technology grew out of the state-affiliated Chinese Academy of Sciences and launched as a commercial enterprise in 2015.  [6]  CloudWalk's IPO will make it the second of China's leading AI start-ups, known as the four \"AI dragons,\" to go public after SenseTime listed on the Hong Kong Stock Exchange in late December 2021,  amidst considerable controversy  .  [7] \n",
      "Research and Development\n",
      "\n",
      "PLA researchers develop AI system enabling satellites to track targets. The South China Morning Post  reports  on an article authored by researchers at the PLA's Space Engineering University who developed an AI system that was able to achieve a 95 percent success rate in tracking targets from a video feed from the Jilin-1 satellite.  [8]  According to the article, the application could enable even low-cost satellites to track targets. The research appeared in Fire Control and Command Control, a PRC peer-reviewed journal published by state-owned defense conglomerate China North Industries Corporation (NORINCO).  [9]  According to the report, unlike previous systems, this AI system was able to track flying aircraft and moving cars and to reacquire targets after they were temporarily lost after making sharp turns or going through a bridge or tunnel. This AI system may lack a real-time tracking capability, however, because the video feed must be transmitted to a ground station and then processed by a computing center. The article noted that newer PRC satellites have been equipped with processors that could be uploaded with the tracking algorithm.\n",
      "Beijing Academy of Artificial Intelligence (BAAI) apologizes after Google Brain research scientist exposes plagiarism in one of its machine learning research publications. On April 8, Nicholas Carlini, a research scientist with Google Brain, posted an article on his website  describing how a recently published paper \"plagiarized several paragraphs\" of his work on deduplicating training data for language models and \"copied from at least a dozen other papers.\"  [10]  Carlini's original paper described \"deduplication tools\" to improve the performance of language models.  [11]  The scandal surrounds the paper, titled \"A Roadmap for Big Model,\" which is meant to serve as an academic review of the latest in machine learning techniques and the state of Big Model applications.  [12]  The \"Roadmap\" article listed over 100 authors representing some of China's most prestigious institutions, such as Tsinghua University, Peking University, BAAI, and the China Academy of Sciences, and industry giants, such as ByteDance, Huawei, Tencent, and JD.com.  [13]  On April 14, BAAI posted an apology for the plagiarism on  Twitter  . An official BAAI  statement  on the issue stated that the authors were asked to conduct a \"rigorous review\" of the article's content and that \"a third-party expert panel will be assembled to conduct an independent investigation of the issue, and those identified as responsible will be held accountable.\"  [14] \n",
      "NOTES\n",
      "\n",
      "\n",
      " [1]  Ke Shi, Tong Bo, and Yang Kuo, \"Strengthen Assessments of Intelligent Command Systems\" (), PLA Daily, Apr. 12, 2022,  http://www.81.cn/jfjbmap/content/2022-04/12/content_313461.htm  .\n",
      "\n",
      "\n",
      " [2]  \"Notice on Launching the Special Action of 'Qinglang 2022 Comprehensive Algorithm Governance' (\"2022\"), Cyberspace Administration of China, Apr. 8, 2022,  http://www.cac.gov.cn/2022-04/08/c_1651028524542025.htm  ; Graham Webster, \"Translation: Notice on Conducting the 'Clear 2022 Comprehensive Governance of Algorithms' Special Action,\" DigiChina, Apr. 11, 2022,  https://digichina.stanford.edu/work/translation-notice-on-conducting-the-clear-2022-comprehensive-governance-of-algorithms-special-action/  .\n",
      "\n",
      "\n",
      " [3]  Zheping Huang, \"China Targets Big Tech's Algorithms as Crackdown Persists,\" Bloomberg, Apr. 7, 2022,  https://www.bloomberg.com/news/articles/2022-04-08/china-targets-tech-giants-for-abusing-online-content-algorithms  .\n",
      "\n",
      "\n",
      " [4]  \"Outline of the Medium and Long-term Development Plan for Scientific and Technological Innovation in the Transportation Field (2021-2035) ((2021-2035)), www.gov.cn, Jan. 24, 2022 (published Apr. 6, 2022),  http://www.gov.cn/zhengce/zhengceku/2022-04/06/content_5683595.htm  .\n",
      "\n",
      "\n",
      " [5]  \"AI Firm CloudWalk Gets Green Light for Shanghai IPO,\" Pandaily, Apr. 7, 2022,  https://pandaily.com/ai-firm-cloudwalk-gets-green-light-for-shanghai-ipo/  .\n",
      "\n",
      "\n",
      " [6]  Zhang Jing, \"'AI Four Little Dragon' Second Chinese Firm IPO: CloudWalk Technology Registration Approved\" (\"AI \" IPO), The Paper, Apr. 7, 2022,  https://www.thepaper.cn/newsDetail_forward_17499997  .\n",
      "\n",
      "\n",
      " [7]  \"SenseTime Shares Up 150% Since Late December IPO,\" Reuters, Jan. 4, 2022,  https://www.reuters.com/business/sensetime-shares-up-150-since-late-december-ipo-2022-01-04/  .\n",
      "\n",
      "\n",
      " [8]  Stephen Chen, \"Chinese AI Turns Commercial Satellite Into a Spy Tracker Able to Follow Small Objects With Precision: Paper,\" South China Morning Post, Apr. 7, 2022,  https://www.scmp.com/news/china/science/article/3173285/chinese-ai-turns-commercial-satellite-spy-tracker-able-follow  .\n",
      "\n",
      "\n",
      " [9]  Liu Yaosheng, Liao Yurong, Lin Cunbao, Li Zhaoming, and Ni Shuyan, \"Video Satellite Target Tracking Algorithm Based On Kernel Correlation Filter\" (), Fire Control and Command Control (), No. 47, Issue 2, (Feb. 2022).\n",
      "\n",
      "\n",
      " [10]  Nicholas Carlini, \"A Case of Plagiarism in Machine Learning Research,\" Apr. 8, 2022,  https://nicholas.carlini.com/writing/2022/a-case-of-plagarism-in-machine-learning.html  .\n",
      "\n",
      "\n",
      " [11]  Katherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck, Chris Callison-Burch, Nicholas Carlini, \"Deduplicating Training Data Makes Language Models Better,\" arXiv, Mar. 24, 2022,  https://arxiv.org/abs/2107.06499  .\n",
      "\n",
      "\n",
      " [12]  Sha Yuan et al., \"A Roadmap for Big Model,\" arXiv, Apr. 2, 2022,  https://arxiv.org/abs/2203.14101  .\n",
      "\n",
      "\n",
      " [13]  Shao Wen, \"AI Research Institute Responds to Academic Controversy of Models Paper\" (AI), The Paper, Apr. 13, 2022,  https://www.thepaper.cn/newsDetail_forward_17591123  .\n",
      "\n",
      "\n",
      " [14]  Beijing Academy of Artificial Intelligence, \"Statement on the Alleged Plagiarism by 'A Roadmap for Big Model,'\" Apr. 13, 2022,  https://www.baai.ac.cn/portal/article/index/cid/4/id/404.html?preview=1  .\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<strong><em></em></strong>\n",
      "<strong><em>PLA Daily</em> discusses requirements for properly evaluating intelligent command systems.</strong>\n",
      "<strong></strong>\n",
      "<strong>The Cyberspace Administration of China (CAC) launches a campaign targeting the use of algorithms in large PRC internet enterprises</strong>\n",
      "<strong>\"Intelligent\" technologies feature heavily in the recently publicized PRC science and technology development plan for the field of transportation.</strong>\n",
      "<strong></strong>\n",
      "<strong>Another one of China's \"AI dragons\" plans to go public.</strong>\n",
      "<strong></strong>\n",
      "<strong>PLA researchers develop AI system enabling satellites to track targets.</strong>\n",
      "<strong>Beijing Academy of Artificial Intelligence (BAAI) apologizes after Google Brain research scientist exposes plagiarism in one of its machine learning research publications.</strong>\n"
     ]
    }
   ],
   "source": [
    "objects = html.find_all('section', class_='content-rows')\n",
    "\n",
    "for o in objects:\n",
    "      paragraph = o.text\n",
    "      headers = o.find_all('strong')\n",
    "      for head in headers:\n",
    "            print(head)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "Welcome to the China AI and Autonomy Report, a biweekly newsletter published by CNA.\n",
      "\n",
      "Evaluations of situational awareness capabilities.  Criteria for evaluating situational awareness capabilities include the ability to assess enemy and friendly dispositions, perceive changes in the situation in real-time, and make predictions about the future battlefield situation.\n",
      "Evaluations of operational decision-making.  Criteria for evaluating operational decisions include the ability to make systematic, rational, and innovative decisions. Effective evaluations include assessing the ability of intelligent command systems to deal with major changes that occur during operations, use standardized procedures, inherit content, and make timely decisions.\n",
      "Evaluations of the ability to formulate plans. Criteria for evaluating the ability to formulate plans include the ability to retrieve and prioritize pre-determined solutions, accurately and rationally match plans to the situation and operational objectives, differentiate between forces, and design operations according to specific plans and capabilities.\n",
      "Evaluations of command and control capabilities. Criteria for evaluating command and control capabilities include the ability to issue timely and complete instructions to each subordinate unit, the ability to command and control multiple units effectively, and the ability to issue commands based on changes to the battlefield situation.\n",
      "\n",
      "Authors in the PLA Daily consider the best way forward for evaluating intelligent command systems, emphasizing the importance of integrating actual command parameters into assessing their effectiveness. PLA researchers have made a breakthrough in using an AI system with a satellite video to better identify and track objects such as planes and cars. The Cyberspace Administration of China has launched a campaign targeting the use of recommendation algorithms in internet companies. The campaign has an explicit focus on large, socially influential internet platforms, which has caused speculation that it is likely an effort to rein in social media giants Tencent and TikTok's parent company Bytedance. PRC ministries have also released a scientific and technology development plan for its transportation sector that seeks to integrate \"intelligent\" technologies into many aspects of transportation, including logistics, infrastructure, traffic monitoring, and vehicles for land, sea, and air transit. Meanwhile, the Beijing Academy of Artificial Intelligence (BAAI) has issued an apology to a Google Brain research scientist who accused PRC researchers from BAAI and other prestigious PRC institutions and corporations of committing plagiarism in a BAAI publication on machine learning. Also of note, this month another of China's \"AI dragons,\" the facial recognition giant CloudWalk Technologies, announced plans to go public.\n",
      "\n",
      "Evaluations of situational awareness capabilities.  Criteria for evaluating situational awareness capabilities include the ability to assess enemy and friendly dispositions, perceive changes in the situation in real-time, and make predictions about the future battlefield situation.\n",
      "Evaluations of operational decision-making.  Criteria for evaluating operational decisions include the ability to make systematic, rational, and innovative decisions. Effective evaluations include assessing the ability of intelligent command systems to deal with major changes that occur during operations, use standardized procedures, inherit content, and make timely decisions.\n",
      "Evaluations of the ability to formulate plans. Criteria for evaluating the ability to formulate plans include the ability to retrieve and prioritize pre-determined solutions, accurately and rationally match plans to the situation and operational objectives, differentiate between forces, and design operations according to specific plans and capabilities.\n",
      "Evaluations of command and control capabilities. Criteria for evaluating command and control capabilities include the ability to issue timely and complete instructions to each subordinate unit, the ability to command and control multiple units effectively, and the ability to issue commands based on changes to the battlefield situation.\n",
      "\n",
      "\n",
      "\n",
      "Evaluations of situational awareness capabilities.  Criteria for evaluating situational awareness capabilities include the ability to assess enemy and friendly dispositions, perceive changes in the situation in real-time, and make predictions about the future battlefield situation.\n",
      "Evaluations of operational decision-making.  Criteria for evaluating operational decisions include the ability to make systematic, rational, and innovative decisions. Effective evaluations include assessing the ability of intelligent command systems to deal with major changes that occur during operations, use standardized procedures, inherit content, and make timely decisions.\n",
      "Evaluations of the ability to formulate plans. Criteria for evaluating the ability to formulate plans include the ability to retrieve and prioritize pre-determined solutions, accurately and rationally match plans to the situation and operational objectives, differentiate between forces, and design operations according to specific plans and capabilities.\n",
      "Evaluations of command and control capabilities. Criteria for evaluating command and control capabilities include the ability to issue timely and complete instructions to each subordinate unit, the ability to command and control multiple units effectively, and the ability to issue commands based on changes to the battlefield situation.\n",
      "\n",
      "PLA Daily discusses requirements for properly evaluating intelligent command systems. The PLA Daily, the official newspaper of the PLA, published an  article  on how best to assess the performance of intelligent command systems.  [1]  The authors write that current assessments of intelligent command systems rely on gaming technologies that overemphasize scores and win-loss rates at the expense of using actual command parameters as measures of effectiveness. They argue that the ability to carry out core command activities (e.g., maintaining situational awareness, rapid decision-making, sound strategic and tactical design, thorough planning, efficient control, and flexible response) is a better criterion for evaluating intelligent command systems. In this respect, the authors argue that evaluations of intelligent command systems involve:\n",
      "\n",
      "Evaluations of situational awareness capabilities.  Criteria for evaluating situational awareness capabilities include the ability to assess enemy and friendly dispositions, perceive changes in the situation in real-time, and make predictions about the future battlefield situation.\n",
      "Evaluations of operational decision-making.  Criteria for evaluating operational decisions include the ability to make systematic, rational, and innovative decisions. Effective evaluations include assessing the ability of intelligent command systems to deal with major changes that occur during operations, use standardized procedures, inherit content, and make timely decisions.\n",
      "Evaluations of the ability to formulate plans. Criteria for evaluating the ability to formulate plans include the ability to retrieve and prioritize pre-determined solutions, accurately and rationally match plans to the situation and operational objectives, differentiate between forces, and design operations according to specific plans and capabilities.\n",
      "Evaluations of command and control capabilities. Criteria for evaluating command and control capabilities include the ability to issue timely and complete instructions to each subordinate unit, the ability to command and control multiple units effectively, and the ability to issue commands based on changes to the battlefield situation.\n",
      "\n",
      "\n",
      "\n",
      "Evaluations of situational awareness capabilities.  Criteria for evaluating situational awareness capabilities include the ability to assess enemy and friendly dispositions, perceive changes in the situation in real-time, and make predictions about the future battlefield situation.\n",
      "Evaluations of operational decision-making.  Criteria for evaluating operational decisions include the ability to make systematic, rational, and innovative decisions. Effective evaluations include assessing the ability of intelligent command systems to deal with major changes that occur during operations, use standardized procedures, inherit content, and make timely decisions.\n",
      "Evaluations of the ability to formulate plans. Criteria for evaluating the ability to formulate plans include the ability to retrieve and prioritize pre-determined solutions, accurately and rationally match plans to the situation and operational objectives, differentiate between forces, and design operations according to specific plans and capabilities.\n",
      "Evaluations of command and control capabilities. Criteria for evaluating command and control capabilities include the ability to issue timely and complete instructions to each subordinate unit, the ability to command and control multiple units effectively, and the ability to issue commands based on changes to the battlefield situation.\n",
      "\n",
      "To conduct these assessments, the authors argue that an effective evaluation team must be composed of functional experts who can evaluate military decision-making, technical experts who can properly evaluate intelligent system technology, and technology specialists who can support the team.\n",
      "\n",
      "Evaluations of situational awareness capabilities.  Criteria for evaluating situational awareness capabilities include the ability to assess enemy and friendly dispositions, perceive changes in the situation in real-time, and make predictions about the future battlefield situation.\n",
      "Evaluations of operational decision-making.  Criteria for evaluating operational decisions include the ability to make systematic, rational, and innovative decisions. Effective evaluations include assessing the ability of intelligent command systems to deal with major changes that occur during operations, use standardized procedures, inherit content, and make timely decisions.\n",
      "Evaluations of the ability to formulate plans. Criteria for evaluating the ability to formulate plans include the ability to retrieve and prioritize pre-determined solutions, accurately and rationally match plans to the situation and operational objectives, differentiate between forces, and design operations according to specific plans and capabilities.\n",
      "Evaluations of command and control capabilities. Criteria for evaluating command and control capabilities include the ability to issue timely and complete instructions to each subordinate unit, the ability to command and control multiple units effectively, and the ability to issue commands based on changes to the battlefield situation.\n",
      "\n",
      "\n",
      "\n",
      "Evaluations of situational awareness capabilities.  Criteria for evaluating situational awareness capabilities include the ability to assess enemy and friendly dispositions, perceive changes in the situation in real-time, and make predictions about the future battlefield situation.\n",
      "Evaluations of operational decision-making.  Criteria for evaluating operational decisions include the ability to make systematic, rational, and innovative decisions. Effective evaluations include assessing the ability of intelligent command systems to deal with major changes that occur during operations, use standardized procedures, inherit content, and make timely decisions.\n",
      "Evaluations of the ability to formulate plans. Criteria for evaluating the ability to formulate plans include the ability to retrieve and prioritize pre-determined solutions, accurately and rationally match plans to the situation and operational objectives, differentiate between forces, and design operations according to specific plans and capabilities.\n",
      "Evaluations of command and control capabilities. Criteria for evaluating command and control capabilities include the ability to issue timely and complete instructions to each subordinate unit, the ability to command and control multiple units effectively, and the ability to issue commands based on changes to the battlefield situation.\n",
      "\n",
      "The Cyberspace Administration of China (CAC) launches a campaign targeting the use of algorithms in large PRC internet enterprises (see original text here and translation from DigiChina  here  ).  [2]  On April 8, CAC announced \"Clear 2022 Comprehensive Governance of Algorithms\"-a campaign to ensure that corporate algorithms comply with the recently adopted  Internet Information Service Algorithmic Recommendation Management Provisions  (hereafter referred to as Provisions). The campaign will be held from April 8 until the beginning of December 2022 and will target \"large-scale websites, platforms, and products that have relatively strong public opinion properties or the capacity for social mobilization.\"\n",
      "\n",
      "Evaluations of situational awareness capabilities.  Criteria for evaluating situational awareness capabilities include the ability to assess enemy and friendly dispositions, perceive changes in the situation in real-time, and make predictions about the future battlefield situation.\n",
      "Evaluations of operational decision-making.  Criteria for evaluating operational decisions include the ability to make systematic, rational, and innovative decisions. Effective evaluations include assessing the ability of intelligent command systems to deal with major changes that occur during operations, use standardized procedures, inherit content, and make timely decisions.\n",
      "Evaluations of the ability to formulate plans. Criteria for evaluating the ability to formulate plans include the ability to retrieve and prioritize pre-determined solutions, accurately and rationally match plans to the situation and operational objectives, differentiate between forces, and design operations according to specific plans and capabilities.\n",
      "Evaluations of command and control capabilities. Criteria for evaluating command and control capabilities include the ability to issue timely and complete instructions to each subordinate unit, the ability to command and control multiple units effectively, and the ability to issue commands based on changes to the battlefield situation.\n",
      "\n",
      " According to Bloomberg  , although the campaign does not mention specific companies, it explicitly targets large, socially influential platforms, a possible reference to ByteDance and Tencent. The campaign is seen as part of a broader effort that began in 2020 to rein in the influence of Big Tech in China.  [3] \n",
      "\n",
      "Evaluations of situational awareness capabilities.  Criteria for evaluating situational awareness capabilities include the ability to assess enemy and friendly dispositions, perceive changes in the situation in real-time, and make predictions about the future battlefield situation.\n",
      "Evaluations of operational decision-making.  Criteria for evaluating operational decisions include the ability to make systematic, rational, and innovative decisions. Effective evaluations include assessing the ability of intelligent command systems to deal with major changes that occur during operations, use standardized procedures, inherit content, and make timely decisions.\n",
      "Evaluations of the ability to formulate plans. Criteria for evaluating the ability to formulate plans include the ability to retrieve and prioritize pre-determined solutions, accurately and rationally match plans to the situation and operational objectives, differentiate between forces, and design operations according to specific plans and capabilities.\n",
      "Evaluations of command and control capabilities. Criteria for evaluating command and control capabilities include the ability to issue timely and complete instructions to each subordinate unit, the ability to command and control multiple units effectively, and the ability to issue commands based on changes to the battlefield situation.\n",
      "\n",
      "\"Intelligent\" technologies feature heavily in the recently publicized PRC science and technology development plan for the field of transportation. On April 6, the Ministry of Transportation and the Ministry of Science and Technology publicly released the \"Outline for the Medium- and Long-term Development Plan for Scientific and Technological Innovation in the Transportation Sector (2021-2035)\" (see from PRC government  here  ).  [4]  By 2035, the plan aims for China to be at the \"forefront of the world\" in terms of its overall level of innovation in science and technology for transportation. The plan's goals that involve the use of \"intelligent\" technologies include the following:\n",
      "\n",
      "Evaluations of situational awareness capabilities.  Criteria for evaluating situational awareness capabilities include the ability to assess enemy and friendly dispositions, perceive changes in the situation in real-time, and make predictions about the future battlefield situation.\n",
      "Evaluations of operational decision-making.  Criteria for evaluating operational decisions include the ability to make systematic, rational, and innovative decisions. Effective evaluations include assessing the ability of intelligent command systems to deal with major changes that occur during operations, use standardized procedures, inherit content, and make timely decisions.\n",
      "Evaluations of the ability to formulate plans. Criteria for evaluating the ability to formulate plans include the ability to retrieve and prioritize pre-determined solutions, accurately and rationally match plans to the situation and operational objectives, differentiate between forces, and design operations according to specific plans and capabilities.\n",
      "Evaluations of command and control capabilities. Criteria for evaluating command and control capabilities include the ability to issue timely and complete instructions to each subordinate unit, the ability to command and control multiple units effectively, and the ability to issue commands based on changes to the battlefield situation.\n",
      "\n",
      "It is important to note that, although the outline lists many technologies that the PRC aspires to advance and adopt, it does not provide details on entities that may be responsible for the development of specific technologies or provide specific budget allocations for R&D.\n",
      "\n",
      "Evaluations of situational awareness capabilities.  Criteria for evaluating situational awareness capabilities include the ability to assess enemy and friendly dispositions, perceive changes in the situation in real-time, and make predictions about the future battlefield situation.\n",
      "Evaluations of operational decision-making.  Criteria for evaluating operational decisions include the ability to make systematic, rational, and innovative decisions. Effective evaluations include assessing the ability of intelligent command systems to deal with major changes that occur during operations, use standardized procedures, inherit content, and make timely decisions.\n",
      "Evaluations of the ability to formulate plans. Criteria for evaluating the ability to formulate plans include the ability to retrieve and prioritize pre-determined solutions, accurately and rationally match plans to the situation and operational objectives, differentiate between forces, and design operations according to specific plans and capabilities.\n",
      "Evaluations of command and control capabilities. Criteria for evaluating command and control capabilities include the ability to issue timely and complete instructions to each subordinate unit, the ability to command and control multiple units effectively, and the ability to issue commands based on changes to the battlefield situation.\n",
      "\n",
      "\n",
      "\n",
      "Evaluations of situational awareness capabilities.  Criteria for evaluating situational awareness capabilities include the ability to assess enemy and friendly dispositions, perceive changes in the situation in real-time, and make predictions about the future battlefield situation.\n",
      "Evaluations of operational decision-making.  Criteria for evaluating operational decisions include the ability to make systematic, rational, and innovative decisions. Effective evaluations include assessing the ability of intelligent command systems to deal with major changes that occur during operations, use standardized procedures, inherit content, and make timely decisions.\n",
      "Evaluations of the ability to formulate plans. Criteria for evaluating the ability to formulate plans include the ability to retrieve and prioritize pre-determined solutions, accurately and rationally match plans to the situation and operational objectives, differentiate between forces, and design operations according to specific plans and capabilities.\n",
      "Evaluations of command and control capabilities. Criteria for evaluating command and control capabilities include the ability to issue timely and complete instructions to each subordinate unit, the ability to command and control multiple units effectively, and the ability to issue commands based on changes to the battlefield situation.\n",
      "\n",
      "Another one of China's \"AI dragons\" plans to go public. On April 6, CloudWalk Technology, \"an AI platform specializing in facial recognition,\" received approval from the China Securities Regulatory Commission to pursue an IPO on the Shanghai Stock Exchange.  [5]  According to a Beijing-based industry publication, CloudWalk will use the funds for a \"human-machine collaborative operating system upgrade project\" referred to as the Qingzhou KaaS Cloud Ecosystem. CloudWalk Technology grew out of the state-affiliated Chinese Academy of Sciences and launched as a commercial enterprise in 2015.  [6]  CloudWalk's IPO will make it the second of China's leading AI start-ups, known as the four \"AI dragons,\" to go public after SenseTime listed on the Hong Kong Stock Exchange in late December 2021,  amidst considerable controversy  .  [7] \n",
      "\n",
      "Evaluations of situational awareness capabilities.  Criteria for evaluating situational awareness capabilities include the ability to assess enemy and friendly dispositions, perceive changes in the situation in real-time, and make predictions about the future battlefield situation.\n",
      "Evaluations of operational decision-making.  Criteria for evaluating operational decisions include the ability to make systematic, rational, and innovative decisions. Effective evaluations include assessing the ability of intelligent command systems to deal with major changes that occur during operations, use standardized procedures, inherit content, and make timely decisions.\n",
      "Evaluations of the ability to formulate plans. Criteria for evaluating the ability to formulate plans include the ability to retrieve and prioritize pre-determined solutions, accurately and rationally match plans to the situation and operational objectives, differentiate between forces, and design operations according to specific plans and capabilities.\n",
      "Evaluations of command and control capabilities. Criteria for evaluating command and control capabilities include the ability to issue timely and complete instructions to each subordinate unit, the ability to command and control multiple units effectively, and the ability to issue commands based on changes to the battlefield situation.\n",
      "\n",
      "\n",
      "\n",
      "Evaluations of situational awareness capabilities.  Criteria for evaluating situational awareness capabilities include the ability to assess enemy and friendly dispositions, perceive changes in the situation in real-time, and make predictions about the future battlefield situation.\n",
      "Evaluations of operational decision-making.  Criteria for evaluating operational decisions include the ability to make systematic, rational, and innovative decisions. Effective evaluations include assessing the ability of intelligent command systems to deal with major changes that occur during operations, use standardized procedures, inherit content, and make timely decisions.\n",
      "Evaluations of the ability to formulate plans. Criteria for evaluating the ability to formulate plans include the ability to retrieve and prioritize pre-determined solutions, accurately and rationally match plans to the situation and operational objectives, differentiate between forces, and design operations according to specific plans and capabilities.\n",
      "Evaluations of command and control capabilities. Criteria for evaluating command and control capabilities include the ability to issue timely and complete instructions to each subordinate unit, the ability to command and control multiple units effectively, and the ability to issue commands based on changes to the battlefield situation.\n",
      "\n",
      "PLA researchers develop AI system enabling satellites to track targets. The South China Morning Post  reports  on an article authored by researchers at the PLA's Space Engineering University who developed an AI system that was able to achieve a 95 percent success rate in tracking targets from a video feed from the Jilin-1 satellite.  [8]  According to the article, the application could enable even low-cost satellites to track targets. The research appeared in Fire Control and Command Control, a PRC peer-reviewed journal published by state-owned defense conglomerate China North Industries Corporation (NORINCO).  [9]  According to the report, unlike previous systems, this AI system was able to track flying aircraft and moving cars and to reacquire targets after they were temporarily lost after making sharp turns or going through a bridge or tunnel. This AI system may lack a real-time tracking capability, however, because the video feed must be transmitted to a ground station and then processed by a computing center. The article noted that newer PRC satellites have been equipped with processors that could be uploaded with the tracking algorithm.\n",
      "\n",
      "Evaluations of situational awareness capabilities.  Criteria for evaluating situational awareness capabilities include the ability to assess enemy and friendly dispositions, perceive changes in the situation in real-time, and make predictions about the future battlefield situation.\n",
      "Evaluations of operational decision-making.  Criteria for evaluating operational decisions include the ability to make systematic, rational, and innovative decisions. Effective evaluations include assessing the ability of intelligent command systems to deal with major changes that occur during operations, use standardized procedures, inherit content, and make timely decisions.\n",
      "Evaluations of the ability to formulate plans. Criteria for evaluating the ability to formulate plans include the ability to retrieve and prioritize pre-determined solutions, accurately and rationally match plans to the situation and operational objectives, differentiate between forces, and design operations according to specific plans and capabilities.\n",
      "Evaluations of command and control capabilities. Criteria for evaluating command and control capabilities include the ability to issue timely and complete instructions to each subordinate unit, the ability to command and control multiple units effectively, and the ability to issue commands based on changes to the battlefield situation.\n",
      "\n",
      "Beijing Academy of Artificial Intelligence (BAAI) apologizes after Google Brain research scientist exposes plagiarism in one of its machine learning research publications. On April 8, Nicholas Carlini, a research scientist with Google Brain, posted an article on his website  describing how a recently published paper \"plagiarized several paragraphs\" of his work on deduplicating training data for language models and \"copied from at least a dozen other papers.\"  [10]  Carlini's original paper described \"deduplication tools\" to improve the performance of language models.  [11]  The scandal surrounds the paper, titled \"A Roadmap for Big Model,\" which is meant to serve as an academic review of the latest in machine learning techniques and the state of Big Model applications.  [12]  The \"Roadmap\" article listed over 100 authors representing some of China's most prestigious institutions, such as Tsinghua University, Peking University, BAAI, and the China Academy of Sciences, and industry giants, such as ByteDance, Huawei, Tencent, and JD.com.  [13]  On April 14, BAAI posted an apology for the plagiarism on  Twitter  . An official BAAI  statement  on the issue stated that the authors were asked to conduct a \"rigorous review\" of the article's content and that \"a third-party expert panel will be assembled to conduct an independent investigation of the issue, and those identified as responsible will be held accountable.\"  [14] \n",
      "\n",
      "Evaluations of situational awareness capabilities.  Criteria for evaluating situational awareness capabilities include the ability to assess enemy and friendly dispositions, perceive changes in the situation in real-time, and make predictions about the future battlefield situation.\n",
      "Evaluations of operational decision-making.  Criteria for evaluating operational decisions include the ability to make systematic, rational, and innovative decisions. Effective evaluations include assessing the ability of intelligent command systems to deal with major changes that occur during operations, use standardized procedures, inherit content, and make timely decisions.\n",
      "Evaluations of the ability to formulate plans. Criteria for evaluating the ability to formulate plans include the ability to retrieve and prioritize pre-determined solutions, accurately and rationally match plans to the situation and operational objectives, differentiate between forces, and design operations according to specific plans and capabilities.\n",
      "Evaluations of command and control capabilities. Criteria for evaluating command and control capabilities include the ability to issue timely and complete instructions to each subordinate unit, the ability to command and control multiple units effectively, and the ability to issue commands based on changes to the battlefield situation.\n",
      "\n",
      " [1]  Ke Shi, Tong Bo, and Yang Kuo, \"Strengthen Assessments of Intelligent Command Systems\" (), PLA Daily, Apr. 12, 2022,  http://www.81.cn/jfjbmap/content/2022-04/12/content_313461.htm  .\n",
      "\n",
      " \n",
      "\t\tIssue 14, May 5, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 13, April 21, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 12, April 7, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 11, March 23, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 10, March 10, 2022\n",
      "\t\n",
      "\n",
      "Issue Index\n",
      "\n",
      " [2]  \"Notice on Launching the Special Action of 'Qinglang 2022 Comprehensive Algorithm Governance' (\"2022\"), Cyberspace Administration of China, Apr. 8, 2022,  http://www.cac.gov.cn/2022-04/08/c_1651028524542025.htm  ; Graham Webster, \"Translation: Notice on Conducting the 'Clear 2022 Comprehensive Governance of Algorithms' Special Action,\" DigiChina, Apr. 11, 2022,  https://digichina.stanford.edu/work/translation-notice-on-conducting-the-clear-2022-comprehensive-governance-of-algorithms-special-action/  .\n",
      "\n",
      " \n",
      "\t\tIssue 14, May 5, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 13, April 21, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 12, April 7, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 11, March 23, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 10, March 10, 2022\n",
      "\t\n",
      "\n",
      "Issue Index\n",
      "\n",
      " [3]  Zheping Huang, \"China Targets Big Tech's Algorithms as Crackdown Persists,\" Bloomberg, Apr. 7, 2022,  https://www.bloomberg.com/news/articles/2022-04-08/china-targets-tech-giants-for-abusing-online-content-algorithms  .\n",
      "\n",
      " \n",
      "\t\tIssue 14, May 5, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 13, April 21, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 12, April 7, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 11, March 23, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 10, March 10, 2022\n",
      "\t\n",
      "\n",
      "Issue Index\n",
      "\n",
      " [4]  \"Outline of the Medium and Long-term Development Plan for Scientific and Technological Innovation in the Transportation Field (2021-2035) ((2021-2035)), www.gov.cn, Jan. 24, 2022 (published Apr. 6, 2022),  http://www.gov.cn/zhengce/zhengceku/2022-04/06/content_5683595.htm  .\n",
      "\n",
      " \n",
      "\t\tIssue 14, May 5, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 13, April 21, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 12, April 7, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 11, March 23, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 10, March 10, 2022\n",
      "\t\n",
      "\n",
      "Issue Index\n",
      "\n",
      " [5]  \"AI Firm CloudWalk Gets Green Light for Shanghai IPO,\" Pandaily, Apr. 7, 2022,  https://pandaily.com/ai-firm-cloudwalk-gets-green-light-for-shanghai-ipo/  .\n",
      "\n",
      " \n",
      "\t\tIssue 14, May 5, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 13, April 21, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 12, April 7, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 11, March 23, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 10, March 10, 2022\n",
      "\t\n",
      "\n",
      "Issue Index\n",
      "\n",
      " [6]  Zhang Jing, \"'AI Four Little Dragon' Second Chinese Firm IPO: CloudWalk Technology Registration Approved\" (\"AI \" IPO), The Paper, Apr. 7, 2022,  https://www.thepaper.cn/newsDetail_forward_17499997  .\n",
      "\n",
      " \n",
      "\t\tIssue 14, May 5, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 13, April 21, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 12, April 7, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 11, March 23, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 10, March 10, 2022\n",
      "\t\n",
      "\n",
      "Issue Index\n",
      "\n",
      " [7]  \"SenseTime Shares Up 150% Since Late December IPO,\" Reuters, Jan. 4, 2022,  https://www.reuters.com/business/sensetime-shares-up-150-since-late-december-ipo-2022-01-04/  .\n",
      "\n",
      " \n",
      "\t\tIssue 14, May 5, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 13, April 21, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 12, April 7, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 11, March 23, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 10, March 10, 2022\n",
      "\t\n",
      "\n",
      "Issue Index\n",
      "\n",
      " [8]  Stephen Chen, \"Chinese AI Turns Commercial Satellite Into a Spy Tracker Able to Follow Small Objects With Precision: Paper,\" South China Morning Post, Apr. 7, 2022,  https://www.scmp.com/news/china/science/article/3173285/chinese-ai-turns-commercial-satellite-spy-tracker-able-follow  .\n",
      "\n",
      " \n",
      "\t\tIssue 14, May 5, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 13, April 21, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 12, April 7, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 11, March 23, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 10, March 10, 2022\n",
      "\t\n",
      "\n",
      "Issue Index\n",
      "\n",
      " [9]  Liu Yaosheng, Liao Yurong, Lin Cunbao, Li Zhaoming, and Ni Shuyan, \"Video Satellite Target Tracking Algorithm Based On Kernel Correlation Filter\" (), Fire Control and Command Control (), No. 47, Issue 2, (Feb. 2022).\n",
      "\n",
      " \n",
      "\t\tIssue 14, May 5, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 13, April 21, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 12, April 7, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 11, March 23, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 10, March 10, 2022\n",
      "\t\n",
      "\n",
      "Issue Index\n",
      "\n",
      " [10]  Nicholas Carlini, \"A Case of Plagiarism in Machine Learning Research,\" Apr. 8, 2022,  https://nicholas.carlini.com/writing/2022/a-case-of-plagarism-in-machine-learning.html  .\n",
      "\n",
      " \n",
      "\t\tIssue 14, May 5, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 13, April 21, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 12, April 7, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 11, March 23, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 10, March 10, 2022\n",
      "\t\n",
      "\n",
      "Issue Index\n",
      "\n",
      " [11]  Katherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck, Chris Callison-Burch, Nicholas Carlini, \"Deduplicating Training Data Makes Language Models Better,\" arXiv, Mar. 24, 2022,  https://arxiv.org/abs/2107.06499  .\n",
      "\n",
      " \n",
      "\t\tIssue 14, May 5, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 13, April 21, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 12, April 7, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 11, March 23, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 10, March 10, 2022\n",
      "\t\n",
      "\n",
      "Issue Index\n",
      "\n",
      " [12]  Sha Yuan et al., \"A Roadmap for Big Model,\" arXiv, Apr. 2, 2022,  https://arxiv.org/abs/2203.14101  .\n",
      "\n",
      " \n",
      "\t\tIssue 14, May 5, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 13, April 21, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 12, April 7, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 11, March 23, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 10, March 10, 2022\n",
      "\t\n",
      "\n",
      "Issue Index\n",
      "\n",
      " [13]  Shao Wen, \"AI Research Institute Responds to Academic Controversy of Models Paper\" (AI), The Paper, Apr. 13, 2022,  https://www.thepaper.cn/newsDetail_forward_17591123  .\n",
      "\n",
      " \n",
      "\t\tIssue 14, May 5, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 13, April 21, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 12, April 7, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 11, March 23, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 10, March 10, 2022\n",
      "\t\n",
      "\n",
      "Issue Index\n",
      "\n",
      " [14]  Beijing Academy of Artificial Intelligence, \"Statement on the Alleged Plagiarism by 'A Roadmap for Big Model,'\" Apr. 13, 2022,  https://www.baai.ac.cn/portal/article/index/cid/4/id/404.html?preview=1  .\n",
      "\n",
      " \n",
      "\t\tIssue 14, May 5, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 13, April 21, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 12, April 7, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 11, March 23, 2022\n",
      "\t\n",
      "\n",
      " \n",
      "\t\tIssue 10, March 10, 2022\n",
      "\t\n",
      "\n",
      "Issue Index\n",
      "\n"
     ]
    }
   ],
   "source": [
    "objects = html.find('div', class_='container')\n",
    "#para = objects.findNext('p') #!!works\n",
    "#print(para.text)\n",
    "\n",
    "items = objects.find_all('p')#, href=True)\n",
    "print(len(items))\n",
    "for i in items:\n",
    "      print(i.text)\n",
    "      parent = i.parent\n",
    "      bullets = parent.findNext('ul')\n",
    "      #bullets = i.findNext('ul')#, href=True)\n",
    "      print(bullets.text)\n",
    "\n",
    "#items = objects.find_all('ul')#, href=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = html.find_all('div', class_='container')\n",
    "print(len(objects))\n",
    "\n",
    "for obj in objects:\n",
    "      items = obj.find_all('p')#, href=True)\n",
    "      print(len(items))\n",
    "      for i in items:\n",
    "            print(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY = 'CNA'\n",
    "pdf_dir = DATA_PATH + QUERY + 'pdfs'\n",
    "\n",
    "if not os.path.exists(pdf_dir): \n",
    "  os.makedirs(pdf_dir)\n",
    "\n",
    "have = set(os.listdir(pdf_dir))\n",
    "\n",
    "# Time out for requests\n",
    "timeout_secs = 10 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_collected.iterrows():\n",
    "      #if row.date >= today - timedelta(days=14):\n",
    "\n",
    "      basename = row.url.split('/')[-1]\n",
    "      fname = os.path.join(pdf_dir, basename)\n",
    "      print(fname)\n",
    "\n",
    "      # try:\n",
    "      if not basename in have:\n",
    "            print('fetching %s into %s' % (row.url, fname))\n",
    "            req = urlopen(row.url, None, timeout_secs)\n",
    "            with open(fname, 'wb') as fp:\n",
    "                  shutil.copyfileobj(req, fp)\n",
    "      else:\n",
    "            print('%s exists, skipping' % (fname, ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulk_text_to_pdf(dir):\n",
    "    done = []\n",
    "    #done_path = []\n",
    "    problem = []\n",
    "\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        #vari.set(\"Writing contents\")\n",
    "        for file in files:\n",
    "            path_to_pdf = os.path.join(root, file)\n",
    "            [stem, ext] = os.path.splitext(path_to_pdf)\n",
    "            if ext == '.pdf':\n",
    "                #vari.set(\"Processing \" + path_to_pdf)\n",
    "                print(\"Processing \" + path_to_pdf)\n",
    "                pdf_contents = parser.from_file(path_to_pdf)\n",
    "                print(pdf_contents)\n",
    "                path_to_txt = stem + '.txt'\n",
    "                name = stem.split('\\\\')[-1]\n",
    "                with open(path_to_txt, 'w', encoding='utf-8') as txt_file:\n",
    "                    print(\"Writing contents to \" + path_to_txt)\n",
    "                    #vari.set(\"Writing contents to \" + path_to_txt)\n",
    "                    if pdf_contents['content'] is None:\n",
    "                        pass\n",
    "                    else:\n",
    "                        #pdf_contents = pdf_contents['content'].replace('\\n\\n\\n\\n', '\\n')\n",
    "                        #pdf_contents = pdf_contents['content'].replace('\\d*\\s\\s\\w*\\.', '', regex=True)\n",
    "                        txt_file.write(pdf_contents['content'])\n",
    "                size = os.path.getsize(path_to_txt)\n",
    "                if size <= 200:\n",
    "                    problem.append(name)\n",
    "                    problem_path.append(path_to_pdf)                    \n",
    "                else:\n",
    "                    done.append(name)\n",
    "                    #done.append(path_to_pdf)                    \n",
    "    #vari.set('Done')\n",
    "    str1 = str('Successfully converted: ' + ', '.join(done))\n",
    "    str2 = str('Possible problems with: ' + ', '.join(problem))\n",
    "    #messagebox.showinfo('Done', str1 + '\\n' + str2)\n",
    "    print(problem_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tika import parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_text_to_pdf(pdf_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for a program and a folder\n",
    "if not shutil.which('pdftotext'): # needs Python 3.3+\n",
    "  print('ERROR: you don\\'t have pdftotext installed. Install it first before calling this script')\n",
    "  sys.exit()\n",
    "\n",
    "if not os.path.exists(DATA_PATH + QUERY + '_txt'):\n",
    "      os.makedirs(DATA_PATH + QUERY + '_txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying paths\n",
    "txt_dir = DATA_PATH + QUERY + '_txt'\n",
    "pdf_dir = DATA_PATH + QUERY + 'pdfs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note- should make a function in utils and import\n",
    "\n",
    "have = set(os.listdir(txt_dir))\n",
    "files = os.listdir(pdf_dir)\n",
    "\n",
    "for i,f in enumerate(files):\n",
    "\n",
    "  txt_basename = f + '.txt'\n",
    "  \n",
    "  if txt_basename in have:\n",
    "    print('%d/%d skipping %s, already exists.' % (i, len(files), txt_basename, ))\n",
    "    continue\n",
    "\n",
    "  pdf_path = os.path.join(pdf_dir, f)\n",
    "  txt_path = os.path.join(txt_dir, txt_basename)\n",
    "  \n",
    "  cmd = \"pdftotext %s %s\" % (pdf_path, txt_path)\n",
    "  os.system(cmd)\n",
    "\n",
    "  print('%d/%d %s' % (i, len(files), cmd))\n",
    "\n",
    "  # check output was made\n",
    "  if not os.path.isfile(txt_path):\n",
    "    # there was an error with converting the pdf\n",
    "    print('there was a problem with parsing %s to text, creating an empty text file.' % (pdf_path, ))\n",
    "    os.system('touch ' + txt_path) # create empty file, but it's a record of having tried to convert\n",
    "\n",
    "  time.sleep(0.01) #  for ctrl+c termination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be nice I should parse these a bit and clean them up\n",
    "# THEN open txt files and insert into DF (naturally create DF)\n",
    "\n",
    "# See txts_to_csv notebook, easy task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response():\n",
    "    #base = test_link\n",
    "    final_url = base_url\n",
    "    #driver = webdriver.Chrome()\n",
    "    \n",
    "    with requests.get(final_url) as response:\n",
    "        #response = requests.get(url, headers=headers)\n",
    "        page_soup = soup(response.content, 'lxml')\n",
    "        return page_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seleniumwire import webdriver  # Import from seleniumwire\n",
    "\n",
    "# Create a new instance of the Firefox driver\n",
    "#driver = webdriver.Chrome()\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--user-agent=\"Mozilla/5.0 (Windows Phone 10.0; Android 4.2.1; Microsoft; Lumia 640 XL LTE) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.135 Mobile Safari/537.36 Edge/12.10166\"')\n",
    "driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "user_agent = driver.execute_script(\"return navigator.userAgent;\")\n",
    "# Go to the Google home page\n",
    "\n",
    "driver.get(base_url_1)\n",
    "\n",
    "# with driver.requests.get(base_url) as response:\n",
    "#     #response = requests.get(url, headers=headers)\n",
    "#     page_soup = soup(response.content, 'lxml')\n",
    "#     #return page_soup\n",
    "\n",
    "# Access requests via the `requests` attribute\n",
    "for request in driver.requests:\n",
    "    if request.response:\n",
    "        print(\n",
    "            request.path,\n",
    "            request.response.status_code,\n",
    "            request.response.headers['Content-Type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f045682951559cbc0979d5d7223b93f289f756c5241efdcb485f4eca938569a1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 ('dri_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
